# Transfer Learning Quick Start Guide
# è¿ç§»å­¦ä¹ å¿«é€Ÿå¼€å§‹æŒ‡å—

## 5-Minute Quick Start / 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### Step 1: Test the modules / æ­¥éª¤1: æµ‹è¯•æ¨¡å—

```bash
python test_transfer_learning.py
```

Expected output / é¢„æœŸè¾“å‡º:
```
âœ“ Configuration module loaded successfully
âœ“ Data splitter working correctly
âœ“ Transfer learning core working correctly
âœ“ Evaluation visualizations working correctly
âœ“ Main pipeline module loaded successfully

ALL TESTS PASSED!
```

### Step 2: Run the pipeline / æ­¥éª¤2: è¿è¡Œæµç¨‹

```bash
python main_transfer_learning.py
```

This will:
è¿™å°†:
1. Load and process training data / åŠ è½½å¹¶å¤„ç†è®­ç»ƒæ•°æ®
2. Train general models / è®­ç»ƒé€šç”¨æ¨¡å‹
3. Save general models / ä¿å­˜é€šç”¨æ¨¡å‹
4. Load test data / åŠ è½½æµ‹è¯•æ•°æ®
5. Split into calibration and evaluation sets / åˆ†å‰²ä¸ºæ ¡å‡†é›†å’Œè¯„ä¼°é›†
6. Evaluate general models / è¯„ä¼°é€šç”¨æ¨¡å‹
7. Fine-tune personalized models / å¾®è°ƒä¸ªæ€§åŒ–æ¨¡å‹
8. Generate comparison reports and visualizations / ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šå’Œå¯è§†åŒ–

### Step 3: Check the results / æ­¥éª¤3: æŸ¥çœ‹ç»“æœ

Results are in `results_transfer_learning/[test_file_name]/`:
ç»“æœåœ¨ `results_transfer_learning/[æµ‹è¯•æ–‡ä»¶å]/`:

```
results_transfer_learning/
â””â”€â”€ [test_file_name]/
    â”œâ”€â”€ plots/                  # ğŸ“Š Visualizations
    â”œâ”€â”€ reports/                # ğŸ“ Text reports
    â””â”€â”€ predictions/            # ğŸ“ˆ Prediction CSV
```

---

## Command-line Options / å‘½ä»¤è¡Œé€‰é¡¹

### Basic usage / åŸºæœ¬ç”¨æ³•:
```bash
python main_transfer_learning.py
```

### Custom test file / è‡ªå®šä¹‰æµ‹è¯•æ–‡ä»¶:
```bash
python main_transfer_learning.py --test-file path/to/your/test.vital
```

### Use different model / ä½¿ç”¨ä¸åŒæ¨¡å‹:
```bash
python main_transfer_learning.py --model-type xgboost
```

### Custom calibration size / è‡ªå®šä¹‰æ ¡å‡†å¤§å°:
```bash
python main_transfer_learning.py --calibration-samples 250
```

### All options combined / ç»„åˆæ‰€æœ‰é€‰é¡¹:
```bash
python main_transfer_learning.py \
    --test-file path/to/test.vital \
    --model-type xgboost \
    --calibration-samples 200 \
    --verbose
```

---

## Configuration Guide / é…ç½®æŒ‡å—

### Essential settings in `config_transfer.py` / `config_transfer.py`ä¸­çš„å…³é”®è®¾ç½®:

#### 1. Model Type / æ¨¡å‹ç±»å‹

```python
GENERAL_MODEL_CONFIG['model_type'] = 'xgboost'  # Recommended / æ¨è
```

Options / é€‰é¡¹:
- `'xgboost'` - Best performance / æœ€ä½³æ€§èƒ½ â­
- `'lightgbm'` - Fast and efficient / å¿«é€Ÿé«˜æ•ˆ
- `'gradient_boosting'` - No dependencies / æ— å¤–éƒ¨ä¾èµ–

#### 2. Calibration Size / æ ¡å‡†å¤§å°

```python
DATA_SPLIT_CONFIG['sample_based']['n_samples'] = 200  # heartbeats
```

Recommendations / å»ºè®®:
- **100 samples**: Fast, may underfit / å¿«é€Ÿ,å¯èƒ½æ¬ æ‹Ÿåˆ
- **200 samples**: Balanced (recommended) / å¹³è¡¡(æ¨è) â­
- **300 samples**: Better accuracy, slower / æ›´å¥½çš„å‡†ç¡®æ€§,æ›´æ…¢

#### 3. Fine-tuning Learning Rate / å¾®è°ƒå­¦ä¹ ç‡

```python
FINE_TUNING_CONFIG['xgboost']['learning_rate'] = 0.01
```

Recommendations / å»ºè®®:
- **0.005**: Very conservative / éå¸¸ä¿å®ˆ
- **0.01**: Recommended / æ¨è â­
- **0.05**: Faster, may overfit / æ›´å¿«,å¯èƒ½è¿‡æ‹Ÿåˆ

---

## Expected Performance / é¢„æœŸæ€§èƒ½

Based on literature and experiments:
åŸºäºæ–‡çŒ®å’Œå®éªŒ:

| Model / æ¨¡å‹ | MAE (mmHg) | MSE | Improvement / æ”¹å–„ |
|-------------|-----------|-----|-------------------|
| General Model / é€šç”¨æ¨¡å‹ | 10-15 | 100-200 | Baseline / åŸºçº¿ |
| Simple Calibration / ç®€å•æ ¡å‡† | 8-12 | 80-150 | 20-30% |
| **Transfer Learning** / è¿ç§»å­¦ä¹  | **3-5** | **20-50** | **60-70%** â­ |

---

## Output Files Explained / è¾“å‡ºæ–‡ä»¶è¯´æ˜

### 1. Visualizations / å¯è§†åŒ– (`plots/`)

#### `transfer_learning_comparison_Systolic.png`
4-panel comparison:
4æ ¼å¯¹æ¯”å›¾:
- Time series (actual vs general vs personalized) / æ—¶é—´åºåˆ—å¯¹æ¯”
- Scatter plot / æ•£ç‚¹å›¾
- Error distribution / è¯¯å·®åˆ†å¸ƒ
- Performance metrics / æ€§èƒ½æŒ‡æ ‡

#### `transfer_learning_comparison_Diastolic.png`
Same as systolic / ä¸æ”¶ç¼©å‹ç›¸åŒ

#### `transfer_learning_improvement_summary.png`
Bar charts showing improvement percentages
æŸ±çŠ¶å›¾æ˜¾ç¤ºæ”¹å–„ç™¾åˆ†æ¯”

### 2. Reports / æŠ¥å‘Š (`reports/`)

#### `transfer_learning_report.txt`
Contains / åŒ…å«:
- Dataset statistics / æ•°æ®é›†ç»Ÿè®¡
- General model metrics / é€šç”¨æ¨¡å‹æŒ‡æ ‡
- Personalized model metrics / ä¸ªæ€§åŒ–æ¨¡å‹æŒ‡æ ‡
- Improvement percentages / æ”¹å–„ç™¾åˆ†æ¯”

### 3. Predictions / é¢„æµ‹ (`predictions/`)

#### `predictions.csv`
Columns / åˆ—:
- `true_systolic` - Actual systolic BP / çœŸå®æ”¶ç¼©å‹
- `pred_systolic_general` - General model prediction / é€šç”¨æ¨¡å‹é¢„æµ‹
- `true_diastolic` - Actual diastolic BP / çœŸå®èˆ’å¼ å‹
- `pred_diastolic_general` - General model prediction / é€šç”¨æ¨¡å‹é¢„æµ‹

---

## Troubleshooting / æ•…éšœæ’é™¤

### Problem: "No module named 'xgboost'"

**Solution / è§£å†³æ–¹æ¡ˆ:**
```bash
pip install xgboost
```

Or use gradient_boosting (no dependencies):
æˆ–ä½¿ç”¨gradient_boosting(æ— ä¾èµ–):
```python
# In config_transfer.py
GENERAL_MODEL_CONFIG['model_type'] = 'gradient_boosting'
```

### Problem: Poor performance / æ€§èƒ½å·®

**Check / æ£€æŸ¥:**
1. Calibration size too small? Try 200-300 samples / æ ¡å‡†å¤§å°å¤ªå°?å°è¯•200-300æ ·æœ¬
2. Learning rate too high? Try 0.01 or 0.005 / å­¦ä¹ ç‡å¤ªé«˜?å°è¯•0.01æˆ–0.005
3. Enable early stopping / å¯ç”¨early stopping

### Problem: Out of memory / å†…å­˜ä¸è¶³

**Solutions / è§£å†³æ–¹æ¡ˆ:**
1. Use fewer training files / ä½¿ç”¨æ›´å°‘çš„è®­ç»ƒæ–‡ä»¶
2. Reduce `n_estimators` / å‡å°‘æ ‘çš„æ•°é‡
3. Use LightGBM instead of XGBoost / ä½¿ç”¨LightGBMä»£æ›¿XGBoost

---

## Next Steps / ä¸‹ä¸€æ­¥

1. **Experiment with parameters** / å®éªŒå‚æ•°
   - Try different calibration sizes / å°è¯•ä¸åŒçš„æ ¡å‡†å¤§å°
   - Adjust learning rates / è°ƒæ•´å­¦ä¹ ç‡
   - Test different models / æµ‹è¯•ä¸åŒæ¨¡å‹

2. **Analyze results** / åˆ†æç»“æœ
   - Check visualizations in `plots/` / æŸ¥çœ‹å¯è§†åŒ–
   - Read detailed report in `reports/` / é˜…è¯»è¯¦ç»†æŠ¥å‘Š
   - Compare metrics / å¯¹æ¯”æŒ‡æ ‡

3. **Fine-tune for your data** / ä¸ºæ‚¨çš„æ•°æ®å¾®è°ƒ
   - Adjust model hyperparameters / è°ƒæ•´æ¨¡å‹è¶…å‚æ•°
   - Optimize calibration size / ä¼˜åŒ–æ ¡å‡†å¤§å°
   - Experiment with strategies / å®éªŒä¸åŒç­–ç•¥

---

## Getting Help / è·å–å¸®åŠ©

1. **Read the full documentation** / é˜…è¯»å®Œæ•´æ–‡æ¡£
   - `TRANSFER_LEARNING_README.md` - Comprehensive guide / ç»¼åˆæŒ‡å—
   - `transfer_learning.md` - Technical design / æŠ€æœ¯è®¾è®¡

2. **Check the code** / æŸ¥çœ‹ä»£ç 
   - All files have detailed comments / æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰è¯¦ç»†æ³¨é‡Š
   - Bilingual (English + Chinese) / åŒè¯­(è‹±æ–‡+ä¸­æ–‡)

3. **Run tests** / è¿è¡Œæµ‹è¯•
   - `python test_transfer_learning.py` - Verify installation / éªŒè¯å®‰è£…

---

**Happy Experimenting! / å®éªŒæ„‰å¿«!** ğŸš€
